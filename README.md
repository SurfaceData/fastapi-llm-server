# FastAPI LLM Server

This is a bare bones FastAPI based Large Language Model Server.  It's meant for
local prototyping and deployment on AWS.
