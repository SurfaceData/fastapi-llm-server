# FastAPI LLM Server

This is a bare bones FastAPI based Large Language Model Server.  It's meant for
local prototyping and deployment on AWS.

```sh
DOCKER_BUILDKIT=1 docker build -t surface-data/llm-server-gpu -f Dockerfile.gpu .
```
